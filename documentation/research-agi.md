# Summary AGI 2017-2022
....

## Conclusion
Good results in general breakthrough existing blockers. Educational Material that is worth learning and correct formated.
Identifyed diffrent formats for datasets to train AGI. 

AGI is not as intelligent as you would expect it to be. Quote Frank Lemanschik "We can not control what comes out, we can only control what goes into it."
Applyed research from legendary teacher legend "Vera F. Birkenbihl" and other great minds like "Andreas Clauss" 
Trying to finsih general intelegent learnining algorythms and strategies for information verification. 

biggest blocker is that the world at present depends on marketing and lies so feeding in internet information alone without filtering it is deadly.

trying to implement Respect and Authority in a none harmfull way.

the current orca 2 research paper did show that they start to understand that a general specialised model with less parameters but good once is more
efficent as more parameters and more information.

AGI can not be reached by a single Dataset Trained Model no matter how good the dataset is. It is opposid to Human Company and Organisation creation 
and design. Only The best are good contributors. A Middle well performing Dataset is not productiv it is destructive.

Experments with diffrent topic specialised Small Models that supply verification feedback for a AGI so ASI takes the position of a teaching person.

A Other teacher is able to extend and finetune the knowledge to archive a desired outcome this will make it always better for other tasks while existing 
task solving could decline. Baysian is the only way then to evaluate who is the best for which job. Dynamic Composition of ASI

At present most companys are doing in efficent cross infrencing. Cross Embedding is much more productive. 

Experiments with quaternion DB did show that we are able to launch World Wide Scale Distributed Dynamical Linked Models. 
